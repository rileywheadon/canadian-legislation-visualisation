{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af846f32-76a2-4e22-acc2-2e36d41936fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d3418fe-ad41-411e-8e0a-f51824c8c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.parl.ca/legisinfo/en/bill/\"\n",
    "\n",
    "# Define bill object\n",
    "class Bill:\n",
    "    def __init__(self, id_, name = None, title = None, constituency = None):\n",
    "        self.id_ = id_\n",
    "        self.name = name\n",
    "        self.title = title\n",
    "        self.constituency = constituency\n",
    "        \n",
    "    def __str__(self):\n",
    "        output = \"\\n\".join([\n",
    "            \"ID: {id_}\", \n",
    "            \"Name: {name}\",\n",
    "            \"Title: {title}\",\n",
    "            \"Constituency: {constituency}\"\n",
    "        ]).format(\n",
    "            id_ = self.id_,\n",
    "            name = self.name,\n",
    "            title = self.title,\n",
    "            constituency = self.constituency\n",
    "        )  \n",
    "        return output\n",
    "\n",
    "# Helper function to get names from the link URL\n",
    "def linkParser(link):\n",
    "    link = link.split('en/')[1].split('(')[0]\n",
    "    link = ' '.join(link.split('-'))\n",
    "    return link.title()\n",
    "\n",
    "# Helper function to remove titles (i.e. Senator or Honorable)\n",
    "def titleParser(name):\n",
    "    name = name.replace('Sen.', '')\n",
    "    name = name.replace('Hon.', '')\n",
    "    return name.strip()\n",
    "            \n",
    "def getSponsorInfo(id_):\n",
    "    \n",
    "    output = Bill(id_)\n",
    "    \n",
    "    try:\n",
    "        page = requests.get(url + id_)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        link = soup.find('section', class_ = \"bill-identity\").find('a')\n",
    "        text = link.text\n",
    "        href = link['href']\n",
    "        \n",
    "    except:\n",
    "        print(output)\n",
    "        return output\n",
    "    \n",
    "    # Assigns default title\n",
    "    output.title = 'Member of Parliament' if 'C' in id_ else 'Senator'\n",
    "        \n",
    "    # File only Case\n",
    "    if 'Text of the bill' in text:\n",
    "        print(output)\n",
    "        return output\n",
    "    \n",
    "    # External Case\n",
    "    if text == 'Leader of the Government in the Senate':\n",
    "        output.title = text\n",
    "        try:\n",
    "            senator_page = requests.get('https:' + link['href'])  \n",
    "            soup = BeautifulSoup(senator_page.content, \"html.parser\")\n",
    "            header = soup.find('div', class_ = \"sc-senator-bio-senatorheader\").find('h1')\n",
    "            output.name = header.text\n",
    "            \n",
    "        except: \n",
    "            print(output)\n",
    "            return output\n",
    "    \n",
    "        if 'Senator' in output.name:\n",
    "            output.name = output.name[8:].split(',')[0].strip()\n",
    "        \n",
    "        print(output)\n",
    "        return output\n",
    "    \n",
    "    # Link Case\n",
    "    titles = ['Prime Minister', 'Minister', 'Leader of Government', 'Leader of the Government', 'Solicitor General', \n",
    "              'President of the Treasury Board', 'Secretary of State', 'President of the Queen\\'s Privy Council']\n",
    "\n",
    "    if any(title in text for title in titles):\n",
    "        output.title = text\n",
    "        output.name = linkParser(href)\n",
    "        \n",
    "        print(output)\n",
    "        return output\n",
    "    \n",
    "    # Name Case\n",
    "    text = text.split('(')\n",
    "    output.name = titleParser(text[0])\n",
    "    \n",
    "    if len(text) > 1 and len(text[1]) > 1:\n",
    "        output.constituency = text[1][:-1].strip()\n",
    "\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283a1d7e-73b8-4c25-a88c-527ec1eff1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the Id column from cleaned_data.csv to get the bills for webscraping\n",
    "data = pd.read_csv('../data/processed/bills_processed.csv')[['Id']]\n",
    "\n",
    "# Get sponsor information on the bills listed in cleaned_data.csv\n",
    "data['SponsorInfo'] = data.apply(lambda x: getSponsorInfo(x.Id), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "805c0c2f-12e2-4138-b2da-b8712e68c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/raw/sponsors.csv', index = False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
